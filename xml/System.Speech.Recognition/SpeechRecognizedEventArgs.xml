<Type Name="SpeechRecognizedEventArgs" FullName="System.Speech.Recognition.SpeechRecognizedEventArgs">
  <TypeSignature Language="C#" Value="public class SpeechRecognizedEventArgs : System.Speech.Recognition.RecognitionEventArgs" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable beforefieldinit SpeechRecognizedEventArgs extends System.Speech.Recognition.RecognitionEventArgs" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.SpeechRecognizedEventArgs" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Speech.Recognition.RecognitionEventArgs</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>情報を提供、 <see cref="E:System.Speech.Recognition.Grammar.SpeechRecognized" />, 、<see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />, 、および <see cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" /> イベントです。</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## 解説  
 A `SpeechRecognized` によってイベントが発生した、 <xref:System.Speech.Recognition.Grammar>, 、<xref:System.Speech.Recognition.SpeechRecognizer> と <xref:System.Speech.Recognition.SpeechRecognitionEngine> クラスです。  
  
 `SpeechRecognized` 1 つ以上の代替認識操作から許容されるために十分な信頼度スコアがある、イベントが生成されます。 認識された語句に関する詳細情報を取得するには、アクセス、 <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> イベントのハンドラーのプロパティです。  
  
 `SpeechRecognizedEventArgs` 派生した、 <xref:System.Speech.Recognition.RecognitionEventArgs> クラスです。  
  
   
  
## 例  
 次の例は、音声認識の文法を読み込んで、音声入力は、共有の認識機能、関連付けられている認識の結果、および音声認識エンジンによって生成される、関連するイベントについて説明するコンソール アプリケーションの一部です。 Windows 音声認識が実行されていない場合、このアプリケーションの開始と Windows 音声認識が開始もします。  
  
 トリガーを miami スライドイン シカゴから「必要など入力を読み上げ、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> イベントです。 "飛行 me ヒューストンからシカゴ"という語句を言うとトリガーは、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> イベントです。  
  
 例では、ハンドラーを使用して、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> イベントを正常に表示するには、語句と、コンソールに含まれるセマンティクスが認識されています。  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
  
        // Create SemanticResultValue objects that contain cities and airport codes.  
        SemanticResultValue chicago = new SemanticResultValue("Chicago", "ORD");  
        SemanticResultValue boston = new SemanticResultValue("Boston", "BOS");  
        SemanticResultValue miami = new SemanticResultValue("Miami", "MIA");  
        SemanticResultValue dallas = new SemanticResultValue("Dallas", "DFW");  
  
        // Create a Choices object and add the SemanticResultValue objects, using  
        // implicit conversion from SemanticResultValue to GrammarBuilder  
        Choices cities = new Choices();  
        cities.Add(new Choices(new GrammarBuilder[] { chicago, boston, miami, dallas }));  
  
        // Build the phrase and add SemanticResultKeys.  
        GrammarBuilder chooseCities = new GrammarBuilder();  
        chooseCities.Append("I want to fly from");  
        chooseCities.Append(new SemanticResultKey("origin", cities));  
        chooseCities.Append("to");  
        chooseCities.Append(new SemanticResultKey("destination", cities));  
  
        // Build a Grammar object from the GrammarBuilder.  
        Grammar bookFlight = new Grammar(chooseCities);  
        bookFlight.Name = "Book Flight";  
  
        // Add a handler for the LoadGrammarCompleted event.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
        // Add a handler for the SpeechRecognized event.  
        recognizer.SpeechRecognized +=   
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(bookFlight);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
      Console.WriteLine();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized:  " + e.Result.Text);  
      Console.WriteLine();  
      Console.WriteLine("Semantic results:");  
      Console.WriteLine("  The flight origin is " + e.Result.Semantics["origin"].Value);  
      Console.WriteLine("  The flight destination is " + e.Result.Semantics["destination"].Value);  
    }  
  }  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.SpeechRecognizedEventArgs" />
    <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
    <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
    <altmember cref="E:System.Speech.Recognition.Grammar.SpeechRecognized" />
    <altmember cref="T:System.Speech.Recognition.SpeechHypothesizedEventArgs" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
    <altmember cref="T:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs" />
  </Docs>
  <Members />
</Type>