<Type Name="RecognizedPhrase" FullName="System.Speech.Recognition.RecognizedPhrase">
  <TypeSignature Language="C#" Value="public class RecognizedPhrase" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable beforefieldinit RecognizedPhrase extends System.Object" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognizedPhrase" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute>
      <AttributeName>System.Diagnostics.DebuggerDisplay("{Text}")</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>音声認識エンジンで生成された、認識された入力に関する詳細な情報が含まれています。</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## 解説  
 このクラスには、単語や語句を操作中に音声認識、以下の処理に関する詳細情報が含まれています。  
  
-   <xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A> プロパティ参照、 <xref:System.Speech.Recognition.Grammar> 、認識エンジンが、入力を識別するために使用します。  
  
-   <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> プロパティには、単語の正規化されたテキストが含まれています。  
  
-   <xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A> プロパティは、結果に含まれているセマンティクス情報を参照します。 セマンティック情報は、キー名と関連付けられたセマンティック データのディクショナリです。  
  
-   <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> プロパティには順序付けられたコレクションが含まれています <xref:System.Speech.Recognition.RecognizedWordUnit> 各を表すオブジェクトが、入力内の単語を認識します。 各単語単位には、表示形式、構文の形式、および対応する単語の発音情報が含まれています。  
  
-   <xref:System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits%2A> プロパティには、特殊な単語の置換に関する情報が含まれています。  
  
-   <xref:System.Speech.Recognition.RecognizedPhrase.Homophones%2A> と <xref:System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId%2A> プロパティには、同一または類似した発音の代替認識に関する情報が含まれています。  
  
-   値、 <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> プロパティは確信、音声認識エンジンによって割り当てられた認識された語句が、入力と一致している度を示します。  
  
 音声認識エンジンがで認識結果を返す、 <xref:System.Speech.Recognition.RecognitionResult> から継承されるオブジェクト <xref:System.Speech.Recognition.RecognizedPhrase>します。 認識結果 <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> プロパティには順序付けられたコレクションが含まれています <xref:System.Speech.Recognition.RecognizedPhrase> と一致する認識エンジンへの入力の候補は、それぞれのオブジェクト。  
  
   
  
## 例  
 次の例では、ハンドラーを <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=fullName>, 、<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=fullName>, 、または <xref:System.Speech.Recognition.Grammar.SpeechRecognized?displayProperty=fullName> イベントとそれに関連付けられている情報の一部、 <xref:System.Speech.Recognition.RecognitionResult> オブジェクトです。<xref:System.Speech.Recognition.RecognitionResult> クラスは <xref:System.Speech.Recognition.RecognizedPhrase> クラスから派生します。  
  
```csharp  
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
  Console.WriteLine("Recognition result summary:");  
  Console.WriteLine(  
    "  Recognized phrase: {0}\n" +   
    "  Confidence score {1}\n" +   
    "  Grammar used: {2}\n",   
    e.Result.Text, e.Result.Confidence, e.Result.Grammar.Name);  
  
  // Display the semantic values in the recognition result.  
  Console.WriteLine("  Semantic results:");  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine("    The {0} city is {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  Console.WriteLine("  Word summary: ");  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    Console.WriteLine(  
      "    Lexical form ({1})" +  
      " Pronunciation ({0})" +  
      " Display form ({2})",  
      word.Pronunciation, word.LexicalForm, word.DisplayAttributes);  
  }  
  
  // Display information about the audio in the recognition result.  
  Console.WriteLine("  Input audio summary:\n" +  
    "    Candidate Phrase at:       {0} mSec\n" +  
    "    Phrase Length:             {1} mSec\n" +  
    "    Input State Time:          {2}\n" +  
    "    Input Format:              {3}\n",  
    e.Result.Audio.AudioPosition,  
    e.Result.Audio.Duration,  
    e.Result.Audio.StartTime,  
    e.Result.Audio.Format.EncodingFormat);  
  
  // Display information about the alternate recognitions in the recognition result.  
  Console.WriteLine("  Alternate phrase collection:");  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine("    Phrase: " + phrase.Text);  
    Console.WriteLine("    Confidence score: " + phrase.Confidence);  
  }  
}  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
    <altmember cref="T:System.Speech.Recognition.RecognizedWordUnit" />
  </Docs>
  <Members>
    <Member MemberName="Confidence">
      <MemberSignature Language="C#" Value="public float Confidence { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance float32 Confidence" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Confidence" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Single</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
          <see cref="T:System.Speech.Recognition.RecognizedPhrase" /> が特定の入力と一致する確率を表す値 \(認識エンジンによって割り当てられます\) を取得します。</summary>
        <value>語句の正しい認識の確実性の相対測定値。 値は 0.0 から 1.0 までであり、低い数字ほど信頼度が低くなります。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## 解説  
 Confidence scores do not indicate the absolute likelihood that a phrase was recognized correctly. Instead, confidence scores provide a mechanism for comparing the relative accuracy of multiple recognition alternates for a given input. This facilitates returning the most accurate recognition result. For example, if a recognized phrase has a confidence score of 0.8, this does not mean that the phrase has an 80% chance of being the correct match for the input.  It means that the phrase is more likely to be the correct match for the input than other results that have confidence scores less than 0.8.  
  
 A confidence score on its own is not meaningful unless you have alternative results to compare against, either from the same recognition operation or from previous recognitions of the same input. The values are used to rank alternative candidate phrases returned by the <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> property on <xref:System.Speech.Recognition.RecognitionResult> objects.  
  
 Confidence values are relative and unique to each recognition engine. Confidence values returned by two different recognition engines cannot be meaningfully compared.  
  
 A speech recognition engine may assign a low confidence score to spoken input for various reasons, including background interference, inarticulate speech, or unanticipated words or word sequences. If your application is using a <xref:System.Speech.Recognition.SpeechRecognitionEngine> instance, you can modify the confidence level at which speech input is accepted or rejected with one of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> methods. Confidence thresholds for the shared recognizer, managed by <xref:System.Speech.Recognition.SpeechRecognizer>, are associated with a user profile and stored in the Windows registry. Applications should not write changes to the registry for the properties of the shared recognizer.  
  
 The <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> property of the <xref:System.Speech.Recognition.RecognitionResult> object contains an ordered collection of <xref:System.Speech.Recognition.RecognizedPhrase> objects, each of which is a possible match for the input to the recognizer. The alternates are ordered from highest to lowest confidence.  
  
   
  
## 例  
 The following example shows a handler for a <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=fullName>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=fullName>, or <xref:System.Speech.Recognition.Grammar.SpeechRecognized?displayProperty=fullName> event. The example shows information associated with the <xref:System.Speech.Recognition.RecognitionResult> object, some of which is derived from <xref:System.Speech.Recognition.RecognizedPhrase>. The handler displays confidence scores for a recognized phrase as well as for recognition alternates.  
  
```csharp  
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
  Console.WriteLine("Recognition result summary:");  
  Console.WriteLine(  
    "  Recognized phrase: {0}\n" +   
    "  Confidence score {1}\n" +   
    "  Grammar used: {2}\n",   
    e.Result.Text, e.Result.Confidence, e.Result.Grammar.Name);  
  
  // Display the semantic values in the recognition result.  
  Console.WriteLine("  Semantic results:");  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine("    The {0} city is {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  Console.WriteLine("  Word summary: ");  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    Console.WriteLine(  
      "    Lexical form ({1})" +  
      " Pronunciation ({0})" +  
      " Display form ({2})",  
      word.Pronunciation, word.LexicalForm, word.DisplayAttributes);  
  }  
  
  // Display information about the audio in the recognition result.  
  Console.WriteLine("  Input audio summary:\n" +  
    "    Candidate Phrase at:       {0} mSec\n" +  
    "    Phrase Length:             {1} mSec\n" +  
    "    Input State Time:          {2}\n" +  
    "    Input Format:              {3}\n",  
    e.Result.Audio.AudioPosition,  
    e.Result.Audio.Duration,  
    e.Result.Audio.StartTime,  
    e.Result.Audio.Format.EncodingFormat);  
  
  // Display information about the alternate recognitions in the recognition result.  
  Console.WriteLine("  Alternate phrase collection:");  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine("    Phrase: " + phrase.Text);  
    Console.WriteLine("    Confidence score: " + phrase.Confidence);  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Alternates" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognizer" />
      </Docs>
    </Member>
    <Member MemberName="ConstructSmlFromSemantics">
      <MemberSignature Language="C#" Value="public System.Xml.XPath.IXPathNavigable ConstructSmlFromSemantics ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Xml.XPath.IXPathNavigable ConstructSmlFromSemantics() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognizedPhrase.ConstructSmlFromSemantics" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Xml.XPath.IXPathNavigable</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>
          <see cref="T:System.Speech.Recognition.RecognizedPhrase" /> オブジェクトのセマンティクス情報のセマンティクス マークアップ言語 \(SML\) ドキュメントを返します。</summary>
        <returns>セマンティクスの SML 記述を返す、 <see cref="T:System.Speech.Recognition.RecognizedPhrase" /> として、 [XPath](http://msdn.microsoft.com/library/ms256115.aspx) ナビゲート可能なオブジェクトです。</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## 解説  
 セマンティック マークアップ言語 \(SML\) については、次を参照してください。、 [Semantic Markup Language Reference](http://msdn.microsoft.com/ja-jp/f9d83443-2cac-49bc-a447-210feda62f5d)です。  
  
   
  
## 例  
 次の例では、メソッドは、認識された語句のセマンティクスの SML を含む文字列を返します。  
  
```  
private string GetSemanticsSML(RecognizedPhrase result)  
{  
  if (result.Semantics.Count > 0)  
  {  
    return result.ConstructSmlFromSemantics().CreateNavigator().OuterXml;  
  }  
  else  
  {  
    return null;  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="Grammar">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.Grammar Grammar { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.Grammar Grammar" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Grammar" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.Grammar</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>音声認識エンジンが <see cref="T:System.Speech.Recognition.RecognizedPhrase" /> を返すために使用した <see cref="T:System.Speech.Recognition.Grammar" /> を取得します。</summary>
        <value>音声認識エンジンが入力の特定に使用した文法オブジェクト。</value>
        <remarks>To be added.</remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognizer" />
      </Docs>
    </Member>
    <Member MemberName="HomophoneGroupId">
      <MemberSignature Language="C#" Value="public int HomophoneGroupId { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 HomophoneGroupId" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>語句の同音異義語グループの識別子を取得します。</summary>
        <value>語句の同音異義語グループの識別子。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## 解説  
 音声認識エンジンでは、同じ発音代替の認識に、グループ id を割り当てます。 一意の発音を持つ各代替の認識機能は異義語グループを作成します。 音声認識エンジンの各認識操作の識別子の新しいグループを生成する、識別子使用できませんから代替グリフを比較する独立した認識操作から生成されました。  
  
 たとえば、"tale"、"tail"、および"ale"代替候補を含んだ認識結果、最初の 2 つのバリエーションは、1 つの異義語グループに属しているし、最後の代替は 2 つ目の異義語グループの 1 つのメンバーになります。  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Alternates" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Homophones" />
      </Docs>
    </Member>
    <Member MemberName="Homophones">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt; Homophones { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.RecognizedPhrase&gt; Homophones" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Homophones" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>この認識された語句と同じ発音の代替認識のコレクションを取得します。</summary>
        <value>この認識された語句と同じ発音の代替認識の読み取り専用コレクション。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## 解説  
 このプロパティは、この認識された語句と同じ発音の他のすべての認識候補を返します。  
  
 たとえば、代替、"tale"および"tail"が含まれている、認識結果の homophones コレクションの最初の代替"tale"の場合、含める 2 番目の句では、"tail"です。 「末尾」に、2 つ目の別の homophones コレクションには、最初の句では、"tale"が含まれます。  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Alternates" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId" />
      </Docs>
    </Member>
    <Member MemberName="ReplacementWordUnits">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.Collection&lt;System.Speech.Recognition.ReplacementText&gt; ReplacementWordUnits { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.Collection`1&lt;class System.Speech.Recognition.ReplacementText&gt; ReplacementWordUnits" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.Collection&lt;System.Speech.Recognition.ReplacementText&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>音声認識エンジンが音声からテキストへの正規化の一部として変更したテキストに関する情報を取得します。</summary>
        <value>認識された入力を正規化したときに音声認識エンジンが置き換えたテキストのセクションを記述する <see cref="T:System.Speech.Recognition.ReplacementText" /> オブジェクトのコレクション。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## 解説  
 音声の認識プロセスの一環として、音声認識エンジンは、表示形式に認識された入力を正規化します。  
  
 たとえば、音声指示、「25 ドル」は認識結果を生成します。 場所、 <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> プロパティには、単語、"20"、"5"、"ドル"が含まれています。 および <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> プロパティには、"2,500 ドル"という語句が含まれています。 テキストの正規化の詳細については、次を参照してください。、 <xref:System.Speech.Recognition.ReplacementText> クラスです。  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizedWordUnit" />
        <altmember cref="T:System.Speech.Recognition.ReplacementText" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Text" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Words" />
      </Docs>
    </Member>
    <Member MemberName="Semantics">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.SemanticValue Semantics { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.SemanticValue Semantics" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Semantics" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.SemanticValue</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>認識された語句に関連付けられているセマンティクス情報を取得します。</summary>
        <value>認識された語句に関連付けられているセマンティクス情報。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## 解説  
 音声認識の文法では、セマンティック情報を含めることができます。 音声認識エンジンでは、このような文法の認識結果を生成するとき、文法と認識機能への入力の規則に従って、セマンティクス情報を認識結果に含める可能性があります。 セマンティック情報の詳細については、次を参照してください。 [Understanding Semantic Results](http://msdn.microsoft.com/ja-jp/2a9dbd8b-cf6d-42cd-bbb9-ca0b3e534005) と <xref:System.Speech.Recognition.SemanticResultKey> と <xref:System.Speech.Recognition.SemanticResultValue> クラスです。  
  
   
  
## 例  
 次の例では、認識された語句から特定のセマンティクス情報を取得するメソッドを定義します。 このメソッドが戻るときは、値が取得されなかった場合、セマンティック キー、または null の値を格納します。 このメソッドは、最上位のキーの場合のみを確認します。 セマンティック情報がツリー形式の値に含まれているので、下位レベルのキーは、返されたセマンティック値を使用してアクセスできなければなりません。  
  
```  
static bool TryGetSemanticValue(  
      RecognizedPhrase phrase, string key, out SemanticValue value)  
{  
  value = null;  
  bool found = phrase.Semantics.ContainsKey(key);  
  if (found)  
  {  
    value = phrase.Semantics[key];  
  }  
  
  return found;  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SemanticResultKey" />
        <altmember cref="T:System.Speech.Recognition.SemanticResultValue" />
        <altmember cref="T:System.Speech.Recognition.SemanticValue" />
      </Docs>
    </Member>
    <Member MemberName="Text">
      <MemberSignature Language="C#" Value="public string Text { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string Text" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Text" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>認識された入力から音声認識エンジンによって生成された正規化テキストを取得します。</summary>
        <value>認識された入力から音声認識エンジンによって生成される正規化テキスト。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## 解説  
 音声の認識プロセスの一環として、音声認識エンジンは、表示するフォームに認識された入力の音声からテキストへの正規化を実行します。  
  
 たとえば、音声指示、「25 ドル」は認識結果を生成します。 場所、 <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> プロパティには、単語、"20"、"5"、"ドル"が含まれています。 および <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> プロパティには、"2,500 ドル"という語句が含まれています。 テキストの正規化の詳細については、次を参照してください。 <xref:System.Speech.Recognition.ReplacementText>します。  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Words" />
      </Docs>
    </Member>
    <Member MemberName="Words">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedWordUnit&gt; Words { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.RecognizedWordUnit&gt; Words" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Words" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedWordUnit&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>認識された入力から音声認識エンジンによって生成される単語を取得します。</summary>
        <value>認識された入力に対して音声認識エンジンによって生成される <see cref="T:System.Speech.Recognition.RecognizedWordUnit" /> オブジェクトのコレクション。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## 解説  
 このプロパティには、結果の認識エンジンの音声からテキストへの正規化する前に音声認識エンジンによって、入力から生成される単語が含まれています。  
  
 たとえば、音声指示、「25 ドル」は認識結果を生成します。 場所、 <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> プロパティには、単語、"20"、"5"、"ドル"が含まれています。 および <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> プロパティには、"2,500 ドル"という語句が含まれています。 テキストの正規化の詳細については、次を参照してください。 <xref:System.Speech.Recognition.ReplacementText>します。  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizedWordUnit" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Text" />
      </Docs>
    </Member>
  </Members>
</Type>